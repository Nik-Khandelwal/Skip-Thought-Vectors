{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# NNFL Research Paper Assignment\n",
    "## Skip-Thought Vectors  (Paper- 62)\n",
    "\n",
    "####                  - Nikhil Khandelwal(2016A3PS0192P), Ajnkya Vyas(2016A3PS0246P), Anwesh Bhattacharya (2016B5A70590P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "WPUC-WqSwKJV",
    "outputId": "a4f59cc7-704a-45cf-9426-db5ebd809664"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime, timedelta\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from config import *\n",
    "from model import UniSkip, Encoder\n",
    "from data_loader import DataLoader\n",
    "from vocab import load_dictionary\n",
    "import nearest_neighbors\n",
    "import eval_mpqa\n",
    "import eval_msrp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task:1 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Wq7Mi6BkwUJg",
    "outputId": "6cd2888e-ae16-4a5b-a4e5-c0eeb05ac833"
   },
   "outputs": [],
   "source": [
    "d = DataLoader(\"./data_corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-__gFOkwPYT"
   },
   "outputs": [],
   "source": [
    "mod = UniSkip()\n",
    "if USE_CUDA:\n",
    "    mod.cuda(CUDA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(params=mod.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zROGqdVVwasI"
   },
   "outputs": [],
   "source": [
    "loss_trail = []\n",
    "last_best_loss = None\n",
    "current_time = datetime.utcnow()\n",
    "\n",
    "def debug(i, loss, prev, nex, prev_pred, next_pred):\n",
    "    global loss_trail\n",
    "    global last_best_loss\n",
    "    global current_time\n",
    "\n",
    "    this_loss = loss.data.item()\n",
    "    loss_trail.append(this_loss)\n",
    "    loss_trail = loss_trail[-20:]\n",
    "    new_current_time = datetime.utcnow()\n",
    "    time_elapsed = str(new_current_time - current_time)\n",
    "    current_time = new_current_time\n",
    "    print(\"Iteration {}: time = {} , this_loss = {}\".format(\n",
    "              i, time_elapsed, this_loss))\n",
    "    \n",
    "    print(\"prev = {}\\nnext = {}\\npred_prev = {}\\npred_next = {}\".format(\n",
    "        d.convert_indices_to_sentences(prev),\n",
    "        d.convert_indices_to_sentences(nex),\n",
    "        d.convert_indices_to_sentences(prev_pred),\n",
    "        d.convert_indices_to_sentences(next_pred),\n",
    "    ))\n",
    "    \n",
    "    try:\n",
    "        trail_loss = sum(loss_trail)/len(loss_trail)\n",
    "        if last_best_loss is None or last_best_loss > trail_loss:\n",
    "            print(\"Loss improved from {} to {}\".format(last_best_loss, trail_loss))\n",
    "            \n",
    "            save_loc = \"./skip-best\".format(lr, VOCAB_SIZE)\n",
    "            print(\"saving model at {}\".format(save_loc))\n",
    "            torch.save(mod.state_dict(), save_loc)\n",
    "            \n",
    "            last_best_loss = trail_loss\n",
    "    except Exception as e:\n",
    "       print(\"Couldn't save model because {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "Sg8c5EoXwf4L",
    "outputId": "af39b958-ec0b-46c2-d4c6-21eecb66cbee"
   },
   "outputs": [],
   "source": [
    "print(\"####################### Training model #######################\\n\\n\")\n",
    "\n",
    "# a million iterations\n",
    "for i in range(0, 1000000):\n",
    "    sentences, lengths = d.fetch_batch(32 * 8)\n",
    "\n",
    "    loss, prev, nex, prev_pred, next_pred  = mod(sentences, lengths)\n",
    "    \n",
    "\n",
    "    if i % 200 == 0:\n",
    "        debug(i, loss, prev, nex, prev_pred, next_pred)\n",
    "        print(\"\\n----------------------------------------------------------------------------\\n\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:  Obtaining the nearest neighbors of different sentences scored by cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Gw8T7_JAwhPb",
    "outputId": "145d6d1a-47fb-4d91-b83c-56c84e715a98"
   },
   "outputs": [],
   "source": [
    "class UsableEncoder:\n",
    "    \n",
    "    def __init__(self, loc=\"./skip-best\"):\n",
    "        print(\"Preparing the DataLoader. Loading the word dictionary\")\n",
    "        self.d = DataLoader(sentences=[''], word_dict=load_dictionary('./data_corpus.txt.pkl'))\n",
    "        self.encoder = None\n",
    "        \n",
    "        print(\"Loading encoder from the saved model at {}\".format(loc))\n",
    "        model = UniSkip()\n",
    "        model.load_state_dict(torch.load(loc, map_location=lambda storage, loc: storage))\n",
    "        self.encoder = model.encoder\n",
    "        if USE_CUDA:\n",
    "            self.encoder.cuda(CUDA_DEVICE)\n",
    "    \n",
    "    def encode(self, text):\n",
    "        def chunks(l, n):\n",
    "            for i in range(0, len(l), n):\n",
    "                yield l[i:i + n]\n",
    "        \n",
    "        ret = []\n",
    "        \n",
    "        for chunk in chunks(text, 100):\n",
    "            print(\"encoding chunk of size {}\".format(len(chunk)))\n",
    "            indices = [self.d.convert_sentence_to_indices(sentence) for sentence in chunk]\n",
    "            indices = torch.stack(indices)\n",
    "            indices, _ = self.encoder(indices)\n",
    "            indices = indices.view(-1, self.encoder.thought_size)\n",
    "            indices = indices.data.cpu().numpy()\n",
    "            \n",
    "            ret.extend(indices)\n",
    "        ret = np.array(ret)\n",
    "        \n",
    "        return ret\n",
    "\n",
    "usable_encoder = UsableEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\n",
    "              \"After her outburst, she darted out of the restaurant .\",\n",
    "              \"he ran his hand inside his coat , double-checking that the unopened letter was still there .\",\n",
    "              \"if he had a weapon , he could maybe take out their last imp , and then beat up errol and vanessa .\"\n",
    "             ]\n",
    "nearest_neighbors.generate(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Using the trained model for paraphrase detection and Opinion Polarity datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0fuubUlV38n8"
   },
   "outputs": [],
   "source": [
    "eval_msrp.evaluate(usable_encoder, loc='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "XJPq1HqUFEZb",
    "outputId": "44108f5e-c14c-445d-9f52-45666ce377be"
   },
   "outputs": [],
   "source": [
    "eval_mpqa.evaluate(usable_encoder, loc='./', k=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nnfl-skip-thought.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
